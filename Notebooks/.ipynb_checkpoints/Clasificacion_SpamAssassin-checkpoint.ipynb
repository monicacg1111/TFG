{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "HsHnKvoPEb6P",
   "metadata": {
    "id": "HsHnKvoPEb6P"
   },
   "source": [
    "# <font color='blue'> **Clasificación**\n",
    "<font color='blue'> Preprocesamiento y clasificación para el conjunto de datos SpamAssassin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jOOp1lyxMO7c",
   "metadata": {
    "id": "jOOp1lyxMO7c"
   },
   "source": [
    " ##  **1. Importar dataset**\n",
    " En primer lugar vamos a importar los archivos donde se encuentran nuestros datos. Cada uno posee una estructura distintas, por lo que tendremos que uniformizarlos.\n",
    "A continuación combinaremos los tres datasets para formar nuestro corpus de correos spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d13cbb",
   "metadata": {
    "id": "98d13cbb"
   },
   "outputs": [],
   "source": [
    "#INSTALAR PAQUETES\n",
    "#!pip install pandas\n",
    "#!pip install wordcloud\n",
    "#!pip install imbalanced-learn\n",
    "#!pip install seaborn\n",
    "#!pip install nltk\n",
    "\n",
    "#IMPORTAR PAQUETES\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS #Lista predeterminada de palabras vacías en inglés\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS #Lista predeterminada de palabras vacías en inglés\n",
    "import string\n",
    "import re  #Biblioteca para utilizar expresiones regulares\n",
    "import nltk #Biblioteca para técnicas de PLN\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt') #Datos para tokenizar\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from urlextract import URLExtract\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d7093-10e1-4cd6-9568-0b8c1f11d6b1",
   "metadata": {},
   "source": [
    "**Leer los datos desde el PC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QgSgfBSIPaPj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "QgSgfBSIPaPj",
    "outputId": "65cd53c3-f672-48db-ff84-76c7c76ad53a"
   },
   "outputs": [],
   "source": [
    "#Para leer desde el pc\n",
    "#data1=pd.read_csv(\"../datos/enronSpamSubset.csv\")\n",
    "#data2=pd.read_csv(\"../datos/lingSpam.csv\")\n",
    "data3=pd.read_csv(\"../datos/completeSpamAssassin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JQqtC2l0B9LU",
   "metadata": {
    "id": "JQqtC2l0B9LU"
   },
   "source": [
    "## **2. Preprocesamiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nlnJ4qUHHU3c",
   "metadata": {
    "id": "nlnJ4qUHHU3c"
   },
   "source": [
    "Tras el análisis descriptivo y exploratorio del problema realizado en Visualizacion.ipynb, hemos comprendido mejor cómo se comportan nuestros datos. Ahora procedemos a la transformación de estos a una estructura que permita a los algoritmos de clasificación llegar a su máxima eficiencia.\n",
    "Dicho preprocesamiento se divide en dos:\n",
    "- **Limpieza y representación de los datos:** ya explicado detenidamente durante la fase de visualización\n",
    "- **Transformación de los datos:** realizaremos una selección de características, un balanceo de clases y la vectorización de los términos en un formato aceptable para los algoritmos de clasificación que vamos a aplicar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SnNJBnyrL9js",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnNJBnyrL9js",
    "outputId": "2eb0551c-5087-4aa0-e037-5f64af0697b3"
   },
   "outputs": [],
   "source": [
    "#data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mTB5-OloOZBW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTB5-OloOZBW",
    "outputId": "06e15ece-5f2e-425f-d8ac-9fcf0f48afe6"
   },
   "outputs": [],
   "source": [
    "#data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jux1ALuPOa10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jux1ALuPOa10",
    "outputId": "a62cfea7-2a0e-43d5-c46c-b06cca83532d"
   },
   "outputs": [],
   "source": [
    "data3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BL85a7vIIYUA",
   "metadata": {
    "id": "BL85a7vIIYUA"
   },
   "source": [
    "Modificamos la estructura de los datos para que tengan únicamente 2 columnas: el cuerpo del mensaje (Body) y su etiqueta (Label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7Zj3GncCIOw3",
   "metadata": {
    "id": "7Zj3GncCIOw3"
   },
   "outputs": [],
   "source": [
    "#Quitamos para cada dataset las columnas irrelevantes\n",
    "#data1.drop([\"Unnamed: 0\",\"Unnamed: 0.1\"],inplace=True,axis=1)\n",
    "#data2.drop(\"Unnamed: 0\",inplace=True,axis=1)\n",
    "data3.drop(\"Unnamed: 0\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rvCEkgL6M2JD",
   "metadata": {
    "id": "rvCEkgL6M2JD"
   },
   "source": [
    "### **Limpieza y representación de los datos**\n",
    "Realizamos la misma limpieza de datos que en Visualización.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658dc5f-733b-44d3-9ad1-334ac1343783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que toma un texto y sustituye las contracciones por la expresión completa\n",
    "def quitar_contracciones(texto):\n",
    "    #Definimos un diccionario de contracciones y sus expansiones completas\n",
    "    contracciones = {\n",
    "        r\"ain\\'t\": \"am not\",\n",
    "        r\"aren\\'t\": \"are not\",\n",
    "        r\"can\\'t\": \"cannot\",\n",
    "        r\"can\\'t\\'ve\": \"cannot have\",\n",
    "        r\"\\'cause\": \"because\",\n",
    "        r\"could\\'ve\": \"could have\",\n",
    "        r\"couldn\\'t\": \"could not\",\n",
    "        r\"couldn\\'t\\'ve\": \"could not have\",\n",
    "        r\"didn\\'t\": \"did not\",\n",
    "        r\"doesn\\'t\": \"does not\",\n",
    "        r\"don\\'t\": \"do not\",\n",
    "        r\"hadn\\'t\": \"had not\",\n",
    "        r\"hadn\\'t\\'ve\": \"had not have\",\n",
    "        r\"hasn\\'t\": \"has not\",\n",
    "        r\"haven\\'t\": \"have not\",\n",
    "        r\"he\\'d\": \"he had\",\n",
    "        r\"he\\'d\\'ve\": \"he would have\",\n",
    "        r\"he\\'ll\": \"he will\",\n",
    "        r\"he\\'ll\\'ve\": \"he will have\",\n",
    "        r\"he\\'s\": \"he is\",\n",
    "        r\"how\\'d\": \"how did\",\n",
    "        r\"how\\'d\\'y\": \"how do you\",\n",
    "        r\"how\\'ll\": \"how will\",\n",
    "        r\"how\\'s\": \"how is\",\n",
    "        r\"i\\'d\": \"i had\",\n",
    "        r\"i\\'d\\'ve\": \"i would have\",\n",
    "        r\"i\\'ll\": \"i will\",\n",
    "        r\"i\\'ll\\'ve\": \"i will have\",\n",
    "        r\"i\\'m\": \"i am\",\n",
    "        r\"i\\'ve\": \"i have\",\n",
    "        r\"isn\\'t\": \"is not\",\n",
    "        r\"it\\'d\": \"it had\",\n",
    "        r\"it\\'d\\'ve\": \"it would have\",\n",
    "        r\"it\\'ll\": \"it will\",\n",
    "        r\"it\\'ll\\'ve\": \"it will have\",\n",
    "        r\"it\\'s\": \"it is\",\n",
    "        r\"let\\'s\": \"let us\",\n",
    "        r\"ma\\'am\": \"madam\",\n",
    "        r\"mayn\\'t\": \"may not\",\n",
    "        r\"might\\'ve\": \"might have\",\n",
    "        r\"mightn\\'t\": \"might not\",\n",
    "        r\"mightn\\'t\\'ve\": \"might not have\",\n",
    "        r\"must\\'ve\": \"must have\",\n",
    "        r\"mustn\\'t\": \"must not\",\n",
    "        r\"mustn\\'t\\'ve\": \"must not have\",\n",
    "        r\"needn\\'t\": \"need not\",\n",
    "        r\"needn\\'t\\'ve\": \"need not have\",\n",
    "        r\"o\\'clock\": \"of the clock\",\n",
    "        r\"oughtn\\'t\": \"ought not\",\n",
    "        r\"oughtn\\'t\\'ve\": \"ought not have\",\n",
    "        r\"shan\\'t\": \"shall not\",\n",
    "        r\"sha\\'n\\'t\": \"shall not\",\n",
    "        r\"shan\\'t\\'ve\": \"shall not have\",\n",
    "        r\"she\\'d\": \"she had\",\n",
    "        r\"she\\'d\\'ve\": \"she would have\",\n",
    "        r\"she\\'ll\": \"she will\",\n",
    "        r\"she\\'ll\\'ve\": \"she will have\",\n",
    "        r\"she\\'s\": \"she is\",\n",
    "        r\"should\\'ve\": \"should have\",\n",
    "        r\"shouldn\\'t\": \"should not\",\n",
    "        r\"shouldn\\'t\\'ve\": \"should not have\",\n",
    "        r\"so\\'ve\": \"so have\",\n",
    "        r\"so\\'s\": \"so as\",\n",
    "        r\"that\\'d\": \"that would\",\n",
    "        r\"that\\'d\\'ve\": \"that would have\",\n",
    "        r\"that\\'s\": \"that is\",\n",
    "        r\"there\\'d\": \"there had\",\n",
    "        r\"there\\'d\\'ve\": \"there would have\",\n",
    "        r\"there\\'s\": \"there is\",\n",
    "        r\"they\\'d\": \"they had\",\n",
    "        r\"they\\'d\\'ve\": \"they would have\",\n",
    "        r\"they\\'ll\": \"they will\",\n",
    "        r\"they\\'ll\\'ve\": \"they will have\",\n",
    "        r\"they\\'re\": \"they are\",\n",
    "        r\"they\\'ve\": \"they have\",\n",
    "        r\"to\\'ve\": \"to have\",\n",
    "        r\"wasn\\'t\": \"was not\",\n",
    "        r\"we\\'d\": \"we had\",\n",
    "        r\"we\\'d\\'ve\": \"we would have\",\n",
    "        r\"we\\'ll\": \"we will\",\n",
    "        r\"we\\'ll\\'ve\": \"we will have\",\n",
    "        r\"we\\'re\": \"we are\",\n",
    "        r\"we\\'ve\": \"we have\",\n",
    "        r\"weren\\'t\": \"were not\",\n",
    "        r\"what\\'ll\": \"what will\",\n",
    "        r\"what\\'ll\\'ve\": \"what will have\",\n",
    "        r\"what\\'re\": \"what are\",\n",
    "        r\"what\\'s\": \"what is\",\n",
    "        r\"what\\'ve\": \"what have\",\n",
    "        r\"when\\'s\": \"when is\",\n",
    "        r\"when\\'ve\": \"when have\",\n",
    "        r\"where\\'d\": \"where did\",\n",
    "        r\"where\\'s\": \"where is\",\n",
    "        r\"where\\'ve\": \"where have\",\n",
    "        r\"who\\'ll\": \"who will\",\n",
    "        r\"who\\'ll\\'ve\": \"who will have\",\n",
    "        r\"who\\'s\": \"who is\",\n",
    "        r\"who\\'ve\": \"who have\",\n",
    "        r\"why\\'s\": \"why is\",\n",
    "        r\"why\\'ve\": \"why have\",\n",
    "        r\"will\\'ve\": \"will have\",\n",
    "        r\"won\\'t\": \"will not\",\n",
    "        r\"won\\'t\\'ve\": \"will not have\",\n",
    "        r\"would\\'ve\": \"would have\",\n",
    "        r\"wouldn\\'t\": \"would not\",\n",
    "        r\"wouldn\\'t\\'ve\": \"would not have\",\n",
    "        r\"y\\'all\": \"you all\",\n",
    "        r\"y\\'all\\'d\": \"you all would\",\n",
    "        r\"y\\'all\\'d\\'ve\": \"you all would have\",\n",
    "        r\"y\\'all\\'re\": \"you all are\",\n",
    "        r\"y\\'all\\'ve\": \"you all have\",\n",
    "        r\"you\\'d\": \"you had\",\n",
    "        r\"you\\'d\\'ve\": \"you would have\",\n",
    "        r\"you\\'ll\": \"you will\",\n",
    "        r\"you\\'ll\\'ve\": \"you will have\",\n",
    "        r\"you\\'re\": \"you are\",\n",
    "        r\"you\\'ve\": \"you have\"\n",
    "    }\n",
    "\n",
    "    #Sustituimos las contracciones en el texto\n",
    "    for contraccion, expansion in contracciones.items():\n",
    "        texto = re.sub(contraccion, expansion, texto)\n",
    "\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cTFQW9PJM2gw",
   "metadata": {
    "id": "cTFQW9PJM2gw"
   },
   "outputs": [],
   "source": [
    "def limpieza(dataset):\n",
    "    data = dataset.copy() #Creamos una copia explícita para evitar errores\n",
    "\n",
    "    #Buscamos y eliminamos las instancias duplicadas\n",
    "    data.drop_duplicates(inplace=True)\n",
    "\n",
    "    #Reemplazamos los espacios en blanco con NaN.\n",
    "    #Para ello, usamos una expresión regular para reemplazar cualquier cadena que contenga únicamente espacios en blanco\n",
    "    data['Body'] = data['Body'].replace(r'^\\s*$', pd.NA, regex=True)\n",
    "\n",
    "    # Eliminamos los correos con valores nulos\n",
    "    data.dropna(subset=['Body'], inplace=True)\n",
    "\n",
    "    # Quitamos mayúsculas\n",
    "    data['Body'] = data['Body'].str.lower()\n",
    "\n",
    "    # Reemplazamos las URLs por el token 'URL'\n",
    "    #url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    #data['Body'] = data['Body'].apply(lambda x: re.sub(url_pattern, 'URL', x))\n",
    "\n",
    "    #OTRA OPCIÓN: URLExtract\n",
    "    extractor = URLExtract()\n",
    "    data['Body'] = data['Body'].apply(lambda x: ' '.join(['URL' if extractor.has_urls(word) else word for word in x.split()]))\n",
    "    \n",
    "\n",
    "    #Antes de eliminar los signos de puntuación, eliminamos las contracciones del inglés para que no queden letras sueltas\n",
    "    data['Body'] = data['Body'].apply(quitar_contracciones)\n",
    "\n",
    "    # Eliminamos signos de puntuación\n",
    "    data['Body'] = data['Body'].str.replace(f'[{string.punctuation}]', ' ', regex=True)\n",
    "\n",
    "    # Eliminamos todos los elementos que no sean caracteres alfabéticos\n",
    "    #pattern = \"[^a-zA-Z0-9]\"\n",
    "    pattern = \"[^a-zA-Z ]\"  # Espacio incluido para no eliminar los espacios entre palabras\n",
    "    data['Body'] = data['Body'].apply(lambda x: re.sub(pattern, ' ', x))\n",
    "\n",
    "    # Creamos una lista personalizada de palabras vacías o stop words\n",
    "    stop_words_list = list(ENGLISH_STOP_WORDS)\n",
    "    stop_words_list += [\"subject\"]\n",
    "\n",
    "    # Eliminamos las stop words\n",
    "    data['Body'] = data['Body'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words_list]))\n",
    "\n",
    "    # Eliminamos términos con longitud menor que 2\n",
    "    data['Body'] = data['Body'].apply(lambda x: ' '.join([word for word in x.split() if len(word) > 1]))\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nR8yGbq3NBoc",
   "metadata": {
    "id": "nR8yGbq3NBoc"
   },
   "outputs": [],
   "source": [
    "#data1_clean=limpieza(data1)\n",
    "#data2_clean=limpieza(data2)\n",
    "data3_clean=limpieza(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wlOfXlKl6P8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlOfXlKl6P8a",
    "outputId": "e1938bb8-dc5d-4aab-d399-23b7c7cbc66d"
   },
   "outputs": [],
   "source": [
    "data_clean = data3_clean\n",
    "\n",
    "# Verificar la información del DataFrame\n",
    "print(data_clean.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HQZI7Dt4V04j",
   "metadata": {
    "id": "HQZI7Dt4V04j"
   },
   "source": [
    "### **Selección de características**\n",
    "\n",
    "Debido a que cuando vectoricemos el conjunto de datos, las características serán las palabras y los valores de estas la frecuencia en el correo, queremos quitar **características irrelevantes** eliminado las palabras cuya frecuencia total sea casi nula, pues no aportan gran cosa.\n",
    "\n",
    "Realizamos esta selección antes que nada, pues al aplicar el balanceo de clases tendremos muchas más palabras y esto puede afectar al rendimiento, y también puede distorsionar la frecuencia real de los términos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dgknGo1FhKuq",
   "metadata": {
    "id": "dgknGo1FhKuq"
   },
   "outputs": [],
   "source": [
    "def seleccion_caracteristicas(data):\n",
    "    #Contar frecuencia de cada palabra en todo el dataset\n",
    "    all_words = ' '.join(data['Body']).split()\n",
    "    word_freq = Counter(all_words)\n",
    "    \n",
    "    # Filtrar palabras con frecuencia menor igual que 5\n",
    "    data['Body'] = data['Body'].apply(lambda x: ' '.join([word for word in x.split() if word_freq[word] > 5]))\n",
    "\n",
    "    #Mostramos las palabras después del filtrado\n",
    "    all_words = ' '.join(data['Body']).split()\n",
    "    word_freq = Counter(all_words)\n",
    "    # Mostrar los 50 primeros términos y sus frecuencias\n",
    "    top_words = list(word_freq.items())[:50]\n",
    "    print(top_words)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c--4TCW_hnCp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c--4TCW_hnCp",
    "outputId": "b38923cb-1266-4737-8d6f-965c22991fac"
   },
   "outputs": [],
   "source": [
    "data=seleccion_caracteristicas(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peyAqzEFhsTM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "peyAqzEFhsTM",
    "outputId": "03822c52-0916-4a38-923e-c4d432a15c12"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05f87f",
   "metadata": {
    "id": "8c05f87f"
   },
   "source": [
    "### **Balanceo de clases**\n",
    "\n",
    "En la fase de visualización vimos que las clases están bastante desbalanceadas. Para resolver este problema, vamos a aplicar **sobremuestreo**. Para ello, usaremos la función `RandomOverSampler` de la biblioteca `imbalanced-learn`. `RandomOverSampler` va replicando aleatoriamente las instancias de la clase minoritaria hasta alcanzar un equilibrio deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606e65e",
   "metadata": {
    "id": "f606e65e"
   },
   "outputs": [],
   "source": [
    "#Función para visualizar la distribución de las clases (para ver si hay desbalanceo)\n",
    "def distribucion(data, title):\n",
    "    #Calculo la cantidad de correos electrónicos en cada clase\n",
    "    class_distribution = data['Label'].value_counts()\n",
    "    class_distribution = class_distribution.sort_index() #Simplemente para que la clase 0 aparezca primero\n",
    "\n",
    "    # Visualizar la distribución de las clases\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    class_distribution.plot(kind='bar', color= ['#45D2EB', '#FF5733'])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Clase')\n",
    "    plt.ylabel('Cantidad de Correos Electrónicos')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.show()\n",
    "\n",
    "    print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6yb1HDjzXErY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "6yb1HDjzXErY",
    "outputId": "93626ffc-ae4e-4d98-b213-435ff0058b6d"
   },
   "outputs": [],
   "source": [
    "distribucion(data, \"Distribución del dataset (Spam=1, Ham=0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52JetyCLXls6",
   "metadata": {
    "id": "52JetyCLXls6"
   },
   "source": [
    "Procedemos a aplicar sobremuestreo de la clase minoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ea8d7",
   "metadata": {
    "id": "f57ea8d7"
   },
   "outputs": [],
   "source": [
    "def sobremuestreo(data):\n",
    "    # Separamos las características y las etiquetas\n",
    "    X = data.drop('Label', axis=1)  # características\n",
    "    y = data['Label']  # etiquetas\n",
    "    \n",
    "    # Aplico el sobremuestreo\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = oversample.fit_resample(X, y)\n",
    "    \n",
    "    # Concatenamos las características y las etiquetas en un nuevo DataFrame\n",
    "    data_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.DataFrame(y_resampled, columns=['Label'])], axis=1)\n",
    "    \n",
    "    # Ahora 'data_resampled' contiene el conjunto de datos con clases balanceadas\n",
    "    return data_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea311d-c4ac-409c-b8d7-0ff5e471fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled=sobremuestreo(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2eae68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "eb2eae68",
    "outputId": "47f70328-79a7-4f16-a920-6115bcb5c3ba"
   },
   "outputs": [],
   "source": [
    "data_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ba6e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "182ba6e0",
    "outputId": "f3be90eb-5dc6-484f-d9ea-cd5b2bf19c33"
   },
   "outputs": [],
   "source": [
    "distribucion(data_resampled, \"Nueva distribución (Spam=1, Ham=0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nFAX2MLIRWRL",
   "metadata": {
    "id": "nFAX2MLIRWRL"
   },
   "source": [
    "### **División del conjunto de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7BksxaoJO-bu",
   "metadata": {
    "id": "7BksxaoJO-bu"
   },
   "outputs": [],
   "source": [
    "data=data_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uKWNEgYgRM8Q",
   "metadata": {
    "id": "uKWNEgYgRM8Q"
   },
   "outputs": [],
   "source": [
    "#Función para dividir el conjunto de datos en entrenamiento y prueba\n",
    "def division_datos(data):\n",
    "    X= data[\"Body\"] #Atributos (sólo hay uno)\n",
    "    y= data[\"Label\"] #Etiquetas\n",
    "    X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=42) #Dividimos en conjunto de entrenamiento y de prueba (20% prueba)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac1764-9c80-4165-9428-c46ac892d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= division_datos(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bceac4b",
   "metadata": {
    "id": "7bceac4b"
   },
   "source": [
    "### **Vectorización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8b545",
   "metadata": {
    "id": "4ec8b545"
   },
   "outputs": [],
   "source": [
    "#Función para vectorizar el conjunto de datos\n",
    "def vectorizacion(X_train, X_test, tipo):\n",
    "    if tipo==\"binary\":\n",
    "        vectorizer=CountVectorizer(binary=True) #Vectorización binaria: las características toman el valor 1 si el término aparece, y 0 si no aparece\n",
    "    elif tipo==\"count\":\n",
    "        vectorizer=CountVectorizer() #Vectorización por conteo: las características toman el valor del número de apariciones de cada término\n",
    "    elif tipo==\"tfidf\":\n",
    "        vectorizer=TfidfVectorizer()\n",
    "    else:\n",
    "        print(\"Error. Indica el tipo de vectorización: 'count', 'binary'  o 'tfidf'.\")\n",
    "        return\n",
    "    X_train=vectorizer.fit_transform(X_train)\n",
    "    X_test=vectorizer.transform(X_test)\n",
    "    #print(vectorizer.vocabulary_)\n",
    "\n",
    "    return X_train, X_test, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084faeb7",
   "metadata": {
    "id": "084faeb7"
   },
   "outputs": [],
   "source": [
    "#Obtenemos los conjuntos de entrenamiento y test aplicándoles los vectorizadores\n",
    "\n",
    "#Vectorizador para Naive Bayes Bernoulli\n",
    "#X_train_0, X_test_0, vectorizer_0= vectorizacion(X_train, X_test, \"binary\") \n",
    "\n",
    "#Vectorizador para el resto de modelos\n",
    "#X_train_1, X_test_1, vectorizer_1= vectorizacion(X_train, X_test, \"count\") \n",
    "X_train_2, X_test_2, vectorizer_2= vectorizacion(X_train, X_test, \"tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wowKYFc8Rh-G",
   "metadata": {
    "id": "wowKYFc8Rh-G"
   },
   "source": [
    "## **3. Búsqueda del mejor modelo**\n",
    "\n",
    "En esta sección realizamos una **búsqueda de hiperparámetros** con el fin de encontrar los valores más óptimos para cada modelo. Usaremos siempre la representación TF-IDF para nuestros datos, pues es la que demostró mejores resultados en el Notebook general.\n",
    "\n",
    "- Para SVC usamos `RandomizedSearchCV` ya que tenemos muchos hiperparámetros y tarda mucho tiempo.\n",
    "- Para NB Multinomial usamos `GridSearchCV`.\n",
    "\n",
    "Como ahora nuestro conjunto de datos es el doble de pequeño, no tenemos problemas con SVC relacionados con el tiempo de ejecución, por lo que podemos fijar `n_iters=10` en `RandomizedSearchCV`. Cada iteración tarda entre 0 y 20 segundos.\n",
    "\n",
    "**Nota**: Fijamos una semilla `random_state=42` para siempre obtener los mismos resultados y no depender de la aleatoriedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53b15e-784b-4a57-ba27-faa674816aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busqueda_hiperparametros(param_grid, clasificador, X_train, y_train, name):\n",
    "    #Definimos el método de validación cruzada\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    #Definición de la herramienta de búsqueda: GridSearchCV o RandomizedSearchCV\n",
    "    if clasificador==SVC: #Lo hacemos random y con 10 iteraciones para que no tarde demasiado\n",
    "        grid = RandomizedSearchCV(SVC(random_state=42), param_grid, n_iter=10, cv=cv, scoring='accuracy', random_state=42, verbose=2)\n",
    "        #Ponemos random_state=42 para que siempre se ejecuten las mismas combinaciones...\n",
    "    else:\n",
    "        grid = GridSearchCV(clasificador(), param_grid, cv=cv, scoring='accuracy', verbose=2)\n",
    "    \n",
    "    #Ejecutamos la búsqueda de hiperparámetros\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"{name} best parameters: {grid.best_params_}\")\n",
    "    print(f\"{name} best CV accuracy: {grid.best_score_}\\n\\n\")\n",
    "\n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe610ae",
   "metadata": {
    "id": "abe610ae"
   },
   "source": [
    "### **Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32452869-9af8-48c5-93b1-225f3c4faed0",
   "metadata": {},
   "source": [
    "#### Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acbb75-7a80-4ecd-825c-c6ab5762859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_NB = {\n",
    "        'alpha': [1.0, 0.5, 0.2, 0.1, 0.01, 0.001, 0]  # Diferentes valores de alpha para probar\n",
    "    }\n",
    "#best_params_NB_1=busqueda_hiperparametros(param_grid_NB, MultinomialNB, X_train_1, y_train, \"NB Multinomial (Count)\")\n",
    "best_params_NB_2=busqueda_hiperparametros(param_grid_NB, MultinomialNB, X_train_2, y_train, \"NB Multinomial (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vxb4fMzCrEeP",
   "metadata": {
    "id": "vxb4fMzCrEeP"
   },
   "source": [
    "### **Support Vector Machines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce58322-693b-4350-af53-fe462ab7245a",
   "metadata": {},
   "source": [
    "#### SVC\n",
    "Debido al alto número de combinaciones de hiperparámetros de SVC, vamos a realizar la búsqueda de los mejores hiperparámetros con `RandomizedSearchCV`, el cual prueba `n_iter` combinaciones distintas y se queda con la mejor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45301750-2c7c-41a7-aa86-dd0702f8c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_SVC = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 'auto', 0.1, 1, 10],\n",
    "        'kernel': ['rbf', 'linear', 'poly']\n",
    "    }\n",
    "#best_params_SVC_1=busqueda_hiperparametros(param_grid_SVC, SVC, X_train_1, y_train, \"SVC (Count)\")\n",
    "best_params_SVC_2=busqueda_hiperparametros(param_grid_SVC, SVC, X_train_2, y_train, \"SVC (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771bc6a-2bb5-407a-bbf7-843bcf313a7d",
   "metadata": {},
   "source": [
    "**Observación**: Como ahora nuestro conjunto de datos tiene muchas menos instancias, `SVC` se ejecuta relativamente rápido, por lo que no necesitamos ejecutar otros algoritmos como LinearSVC y SGDClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fc17a-e724-45a5-aa44-db71c32695d2",
   "metadata": {},
   "source": [
    "#### **Resultados**\n",
    "Observamos que las siguientes configuraciones de hiperparámetros son las que conducen a los mejores modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c73d7-57f9-4b2c-9334-a1a90e4b6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Hiperparámetros del mejor modelo para Naive Bayes Multinomial: \n",
    "    TfidfVectorizer: {best_params_NB_2}\n",
    "    \"\"\")\n",
    "\n",
    "print(f\"\"\"Hiperparámetros del mejor modelo para SVC: \n",
    "    TfidfVectorizer: {best_params_SVC_2}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FtTS6axrbaEp",
   "metadata": {
    "id": "FtTS6axrbaEp"
   },
   "source": [
    "## **4. Entrenamiento y validación del mejor modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jsCvx0hvMkr8",
   "metadata": {
    "id": "jsCvx0hvMkr8"
   },
   "source": [
    "El entrenamiento de modelos de Aprendizaje Automático y la estimación del error fuera de la muestra son cruciales para entender cómo los modelos generalizarán a instancias o datos nuevos, que no fueron considerados durante el entrenamiento. Este apartado aborda cómo se entrenaron los modelos, cómo se estimó el error fuera de la muestra y qué conclusiones podemos extraer de los resultados.\n",
    "\n",
    "\n",
    "**Entrenamiento de los modelos**\n",
    "\n",
    "Los modelos seleccionados fueron entrenados utilizando el conjunto de entrenamiento (`X_train`: espacio de características, `y_train`: etiquetas). Para cada modelo, se utilizaron los mejores hiperparámetros calculados mediante GridSearchCV, asegurando que cada modelo estuviera optimizado. El entrenamiento del modelo consiste en primer lugar en definir el objeto de validación cruzada, y pasarle el modelo declarado. Tras ello, con `model.fit` se entrena el modelo con el conjunto de entrenamiento dado. Así para cada uno de los tres modelos elegidos.\n",
    "\n",
    "\n",
    "**Validación: Estimación del error fuera de la muestra**\n",
    "\n",
    "El error fuera de la muestra se estima utilizando el conjunto de prueba (`X_test`, `y_test`). Esto proporciona una evaluación de cómo cada modelo realiza predicciones sobre datos que no fueron utilizados durante el entrenamiento, simulando cómo el modelo podría comportarse en situaciones del mundo real. La predicción se hace con el conjunto test dado, con `model.predict(X_test)`. Una vez obtenido el resultado de dicha predicción, `y_test_pred`, podemos calcular las medidas de evaluación y rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e675c092-5370-4b3d-9491-bc06d5e59e55",
   "metadata": {},
   "source": [
    "A continuación defino unas funciones de validación y de evaluación genéricas, que sirvan para cualquier modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9daa87-9b71-4692-8c3b-320b44a63caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que calcula las métricas de evaluación y rendimiento, dado y e y_pred\n",
    "def metricas_evaluacion(y, y_pred, y_scores, model_name):\n",
    "    accuracy= accuracy_score(y, y_pred)\n",
    "    precision= precision_score(y, y_pred, average='macro')\n",
    "    recall= recall_score(y, y_pred, average='macro')\n",
    "    f1= f1_score(y, y_pred, average='macro')\n",
    "    conf_matrix=confusion_matrix(y, y_pred)\n",
    "    #class_report = classification_report(y, y_pred)\n",
    "    auc_score = roc_auc_score(y, y_scores) #y_scores contiene las puntuaciones o probabilidades estimadas para la clase positiva, que son necesarias para calcular el AUC\n",
    "    \n",
    "    #Mostramos por pantalla los resultados\n",
    "    print(f\"Resultados para {model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-Score:\", f1)\n",
    "    print(\"AUC Score:\", auc_score)\n",
    "    #print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "    #print(\"\\nClassification Report:\\n\", class_report)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Visualización de la matriz de confusión\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix for ' + model_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ee7fe-351c-41af-848b-96b4b5785c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que entrena y valida un modelo, dado el algoritmo de clasificación y los datos de entrenamiento y test\n",
    "def validacion(algoritmo_clasificacion, parametros, X_train, y_train, X_test, y_test, name):\n",
    "    if algoritmo_clasificacion == SVC:\n",
    "        parametros = parametros.copy()  # Copiar para no modificar el original externamente\n",
    "        parametros['probability'] = True  # Habilitar la estimación de probabilidades\n",
    "        \n",
    "    #Reentrenamos el mejor modelo pero ahora sí con todo el conjunto de entrenamiento\n",
    "    model = algoritmo_clasificacion(**parametros)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    #Realizamos predicciones para el conjunto de entrenamiento\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    #Realizamos predicciones con el conjunto de prueba\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    #Métricas de evaluación para la predicción del conjunto de entrenamiento y_train_pred\n",
    "    print(f\"--- Entrenamiento - {name} ({parametros})---\")\n",
    "    metricas_evaluacion(y_train, y_train_pred, model.predict_proba(X_train)[:, 1], name) \n",
    "    \n",
    "    #Métricas de evaluación para la predicción del conjunto de test y_test_pred\n",
    "    print(f\"--- Prueba - {name} ---\")\n",
    "    metricas_evaluacion(y_test, y_test_pred, model.predict_proba(X_test)[:, 1], name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad4345-06ab-42b5-b927-853005cf7ea4",
   "metadata": {},
   "source": [
    "**NB Multinomial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3bd66-c811-4407-aee5-d05e80d59281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NB_2=validacion(MultinomialNB, best_params_NB_2, X_train_2, y_train, X_test_2, y_test, name=\"NB Multinomial (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d61e1c-efd2-446a-bcbe-0facdcba3ba6",
   "metadata": {},
   "source": [
    "#### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f5fb8-a45b-4de7-8f2e-a84447e7a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SVC_2=validacion(SVC, best_params_SVC_2, X_train_2, y_train, X_test_2, y_test, name=\"SVC (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e634d840-12aa-4977-b7af-96670126c9c6",
   "metadata": {},
   "source": [
    "## **5. Otras representaciones: synsets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79208540-a685-4fa3-a442-d7cb1494c93d",
   "metadata": {},
   "source": [
    "### **Detección de hiperónimos en synsets**\n",
    "Vamos a crear un dataset aparte, donde los términos sean obtenidos a partir de **synsets** de los términos originales. Usaremos los synsets del paquete WordNet de la librería NLTK.\n",
    "De esta forma, estamos intentando agrupar términos que tienen relación. Por ejemplo, podemos observar que las palabras \"dollar\" y \"euro\" pertenecen a la misma categoría: \"monetary_unit\". De hecho no tiene sentido tratarlos como palabras completamente distintas, como lo harían nuestros algoritmos de clasificación sin este procesamiento.\n",
    "\n",
    "A este nuevo dataset le aplicaremos todo el preprocesamiento anterior, y compararemos los resultados con el dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee35fe-70b3-4b96-adfa-3d464eb76234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def obtener_primer_hiperonimo(palabra):\n",
    "    # Lematizamos la palabra antes de obtener los synsets\n",
    "    palabra_lematizada = lemmatizer.lemmatize(palabra)\n",
    "    \n",
    "    # Obtenemos todos los synsets de la palabra lematizada\n",
    "    synsets = wn.synsets(palabra_lematizada)\n",
    "\n",
    "    #Verificar si hay al menos un synset\n",
    "    if synsets:\n",
    "        #Seleccionamos el primer synset\n",
    "        primer_synset = synsets[0]\n",
    "\n",
    "        #Obtenemos los hiperónimos del primer synset\n",
    "        hiperonimos = primer_synset.hypernyms()\n",
    "\n",
    "        # Verificar si el synset tiene hiperónimos\n",
    "        if hiperonimos:\n",
    "            # Seleccionar el primer hiperónimo y obtener el primer lema\n",
    "            primer_hiperonimo = hiperonimos[0].lemmas()[0].name()\n",
    "            return primer_hiperonimo\n",
    "        else:\n",
    "            return palabra #No hay hiperónimos así que dejamos la palabra inicial\n",
    "    else:\n",
    "        return palabra #No hay synsets así que dejamos la palabra inicial\n",
    "\n",
    "# Ejemplo de uso de la función\n",
    "palabra = \"dollar\"\n",
    "hiperonimo = obtener_primer_hiperonimo(palabra)\n",
    "print(f\"El primer hiperónimo de '{palabra}' es: {hiperonimo}\")\n",
    "\n",
    "palabra = \"euro\"\n",
    "hiperonimo = obtener_primer_hiperonimo(palabra)\n",
    "print(f\"El primer hiperónimo de '{palabra}' es: {hiperonimo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1927b-f9ce-462a-974a-c4985612d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplazar_con_hiperonimos(frase):\n",
    "    palabras = frase.split()\n",
    "    palabras_con_hiperonimos = [obtener_primer_hiperonimo(palabra) for palabra in palabras]\n",
    "    frase_transformada = ' '.join(palabras_con_hiperonimos)\n",
    "    return frase_transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc916c-f60c-4399-9a30-c1838a288bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_synsets=data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e8180-5b00-4a7f-91ee-c05d33bcbb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_synsets['Body'] = data_synsets['Body'].apply(reemplazar_con_hiperonimos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145560d-9334-4e3a-a114-1a7135750c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_synsets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf0f62-8a48-467e-abbb-01078a06d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_synsets=seleccion_caracteristicas(data_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb9d070-91cd-40c2-bd52-887da421e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_synsets, X_test_synsets, y_train_synsets, y_test_synsets= division_datos(data_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d00b2-c490-4b44-8a93-ecdb3cea69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_synsets_1, X_test_synsets_1, vectorizer_synsets_1= vectorizacion(X_train_synsets, X_test_synsets, \"count\")\n",
    "X_train_synsets_2, X_test_synsets_2, vectorizer_synsets_2= vectorizacion(X_train_synsets, X_test_synsets, \"tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a57fca-4a20-45e5-8401-193be28be331",
   "metadata": {},
   "source": [
    "**Realizamos los puntos 3 y 4 igual que antes, es decir, hacemos búsqueda de hiperparámetros y luego validamos el mejor modelo, pero únicamente para representación TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ade5df-ced7-4141-9c20-234e88779eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_NB_synsets_2=busqueda_hiperparametros(param_grid_NB, MultinomialNB, X_train_synsets_2, y_train_synsets, \"NB Multinomial Synsets (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520bcefa-fbd6-4f74-ad68-9d332be1d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_SVC_synsets_2=busqueda_hiperparametros(param_grid_SVC, SVC, X_train_synsets_2, y_train_synsets, \"SVC Synsets (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca319f4-13c9-4abd-9256-0d05f5cb5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Hiperparámetros del mejor modelo para Naive Bayes Multinomial: \n",
    "    TfidfVectorizer: {best_params_NB_synsets_2}\n",
    "    \"\"\")\n",
    "\n",
    "print(f\"\"\"Hiperparámetros del mejor modelo para SVC: \n",
    "    TfidfVectorizer: {best_params_SVC_synsets_2}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a4eb94-f80d-482f-9114-06aef8e43a88",
   "metadata": {},
   "source": [
    "## **6. Comparaciones**\n",
    "Realizamos comparaciones entre los resultados obtenidos por los dos clasificadores (NB Multinomial y SVM), con las dos representaciones (términos o synsets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502654ea-ee2a-4305-9ec0-0c3ec328cd9a",
   "metadata": {},
   "source": [
    "#### **Tabla comparativa con las métricas para cada modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae212626-10df-4199-a7a0-656d1e4dbe2e",
   "metadata": {},
   "source": [
    "Mostraremos una tabla para entrenamiento y otra para test. Cada fila de la tabla representará las métricas para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48af36-0245-4605-bf88-0115f453705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_scores, model_name):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Curva ROC - ' + model_name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a25a4-f867-4be2-8f36-a2e690274c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que devuelve todas las métricas para entrenamiento y para prueba\n",
    "def validacion_train_test(algoritmo_clasificacion, parametros, X_train, y_train, X_test, y_test, name):\n",
    "    print(f\"\\nValidando {name}\")\n",
    "    if algoritmo_clasificacion == SVC:\n",
    "        parametros = parametros.copy()  # Copiar para no modificar el original externamente\n",
    "        parametros['probability'] = True  # Habilitar la estimación de probabilidades\n",
    "        \n",
    "    #Reentrenamos el mejor modelo pero ahora sí con todo el conjunto de entrenamiento\n",
    "    model = algoritmo_clasificacion(**parametros)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calibración del modelo para poder usar predict_proba en LinearSVC y en SGDClassifier\n",
    "    if algoritmo_clasificacion == LinearSVC or algoritmo_clasificacion == SGDClassifier:\n",
    "        model = CalibratedClassifierCV(model, method='sigmoid', cv='prefit')\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_scores = model.predict_proba(X_test)[:, 1]  # Probabilidades para la clase positiva\n",
    "    \n",
    "    train_metrics = {\n",
    "        'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "        'Precision': precision_score(y_train, y_train_pred, average='macro'),\n",
    "        'Recall': recall_score(y_train, y_train_pred, average='macro'),\n",
    "        'F1-Score': f1_score(y_train, y_train_pred, average='macro'),\n",
    "        'AUC': roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "    }\n",
    "    test_metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'Precision': precision_score(y_test, y_test_pred, average='macro'),\n",
    "        'Recall': recall_score(y_test, y_test_pred, average='macro'),\n",
    "        'F1-Score': f1_score(y_test, y_test_pred, average='macro'),\n",
    "        'AUC': roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]),\n",
    "        #'y_scores': y_test_scores\n",
    "    }\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plot_roc_curve(y_test, y_test_scores, name)\n",
    "    \n",
    "    return train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be62f124-fb0e-4aa4-ad77-f7648106e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "df_metrics_train = pd.DataFrame(columns=columns)\n",
    "df_metrics_test = pd.DataFrame(columns=columns)\n",
    "\n",
    "#Validar y recopilar métricas para NB Multinomial tf-idf\n",
    "train_metrics_NB_2, test_metrics_NB_2 = validacion_train_test(MultinomialNB, best_params_NB_2, X_train_2, y_train, X_test_2, y_test, \"NB Multinomial\")\n",
    "df_metrics_train = pd.concat([df_metrics_train, pd.DataFrame([['NB Multinomial'] + list(train_metrics_NB_2.values())], columns=columns)], ignore_index=True)\n",
    "df_metrics_test = pd.concat([df_metrics_test, pd.DataFrame([['NB Multinomial'] + list(test_metrics_NB_2.values())], columns=columns)], ignore_index=True)\n",
    "\n",
    "#Validar y recopilar métricas para NB Multinomial tf-idf con synsets\n",
    "train_metrics_NB_synsets_2, test_metrics_NB_synsets_2 = validacion_train_test(MultinomialNB, best_params_NB_synsets_2, X_train_synsets_2, y_train_synsets, X_test_synsets_2, y_test_synsets, \"NB Multinomial Synsets\")\n",
    "df_metrics_train = pd.concat([df_metrics_train, pd.DataFrame([['NB Multinomial Synsets'] + list(train_metrics_NB_synsets_2.values())], columns=columns)], ignore_index=True)\n",
    "df_metrics_test = pd.concat([df_metrics_test, pd.DataFrame([['NB Multinomial Synsets'] + list(test_metrics_NB_synsets_2.values())], columns=columns)], ignore_index=True)\n",
    "\n",
    "#Validar y recopilar métricas para SVC tf-idf\n",
    "train_metrics_SVC_2, test_metrics_SVC_2 = validacion_train_test(SVC, best_params_SVC_2, X_train_2, y_train, X_test_2, y_test, \"SVC\")\n",
    "df_metrics_train = pd.concat([df_metrics_train, pd.DataFrame([['SVC'] + list(train_metrics_SVC_2.values())], columns=columns)], ignore_index=True)\n",
    "df_metrics_test = pd.concat([df_metrics_test, pd.DataFrame([['SVC'] + list(test_metrics_SVC_2.values())], columns=columns)], ignore_index=True)\n",
    "\n",
    "#Validar y recopilar métricas para SVC tf-idf con synsets\n",
    "train_metrics_SVC_synsets_2, test_metrics_SVC_synsets_2 = validacion_train_test(SVC, best_params_SVC_synsets_2, X_train_synsets_2, y_train_synsets, X_test_synsets_2, y_test_synsets, \"SVC Synsets\")\n",
    "df_metrics_train = pd.concat([df_metrics_train, pd.DataFrame([['SVC Synsets'] + list(train_metrics_SVC_synsets_2.values())], columns=columns)], ignore_index=True)\n",
    "df_metrics_test = pd.concat([df_metrics_test, pd.DataFrame([['SVC Synsets'] + list(test_metrics_SVC_synsets_2.values())], columns=columns)], ignore_index=True)\n",
    "\n",
    "# Imprimir los DataFrames finales con todas las métricas\n",
    "print(\"Training Metrics:\")\n",
    "print(df_metrics_train)\n",
    "print(\"\\nTesting Metrics:\")\n",
    "print(df_metrics_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1119a6f-a1ba-447d-b5c0-f35dfcc70489",
   "metadata": {},
   "source": [
    "### Curva ROC\n",
    "También vamos a mostrar la gráfica de la curva ROC para todos los modelos entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89071721-5775-4c4d-83e9-fb68cc6828ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para representar en una gráfica distintas curvas ROC, incluyendo la de un clasificador random\n",
    "def plot_combined_roc_curves(y_tests, y_score_lists, model_names, title=\"Combined ROC Curves\"):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'orange', 'purple', 'brown']\n",
    "    \n",
    "    for i, y_scores in enumerate(y_score_lists):\n",
    "        fpr, tpr, _ = roc_curve(y_tests[i], y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, color=colors[i % len(colors)], lw=2,\n",
    "                 label='ROC curve of {0} (area = {1:0.3f})'.format(model_names[i], roc_auc))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a79f67-1366-417a-8b23-0820c31206d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que devuelve las métricas necesarias para representar la curva ROC\n",
    "def validacion_curvaROC(algoritmo_clasificacion, parametros, X_train, y_train, X_test, y_test, name):\n",
    "    print(f\"\\nValidando {name}\")\n",
    "    if algoritmo_clasificacion == SVC:\n",
    "        parametros = parametros.copy()  # Copiar para no modificar el original externamente\n",
    "        parametros['probability'] = True  # Habilitar la estimación de probabilidades\n",
    "        \n",
    "    #Reentrenamos el mejor modelo pero ahora sí con todo el conjunto de entrenamiento\n",
    "    model = algoritmo_clasificacion(**parametros)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_scores = model.predict_proba(X_test)[:, 1]  # Probabilidades para la clase positiva\n",
    "    \n",
    "    return y_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244073e-46a1-4b02-a496-e460a1312cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [(MultinomialNB, best_params_NB_2, \"NB Multinomial\", \"\"),\n",
    "              (MultinomialNB, best_params_NB_synsets_2, \"NB Multinomial Synsets\", \"synsets\"),\n",
    "              (SVC, best_params_SVC_2, \"SVC\", \"\"),\n",
    "              (SVC, best_params_SVC_synsets_2, \"SVC Synsets\", \"synsets\"),\n",
    "             ]\n",
    "\n",
    "y_tests = []\n",
    "y_scores = []\n",
    "model_names = []\n",
    "\n",
    "for model, params, name, type in model_list:\n",
    "    if type==\"synsets\":\n",
    "        y_test_scores = validacion_curvaROC(model, params, X_train_synsets_2, y_train_synsets, X_test_synsets_2, y_test_synsets, name)\n",
    "        y_tests.append(y_test_synsets)\n",
    "    else:\n",
    "        y_test_scores = validacion_curvaROC(model, params, X_train_2, y_train, X_test_2, y_test, name)\n",
    "        y_tests.append(y_test)\n",
    "        \n",
    "    y_scores.append(y_test_scores) \n",
    "    model_names.append(name)\n",
    "\n",
    "plot_combined_roc_curves(y_tests, y_scores, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2c6695-77b8-4a3a-9c7a-e35fa294fb3e",
   "metadata": {},
   "source": [
    "Observamos que todos los modelos obtienen métricas casi perfectas, y la curva ROC también se aproxima a la de un clasificador perfecto en todos los casos"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
